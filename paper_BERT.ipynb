{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"paper_BERT.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8b2b8713e4a8454595bc00174d2fe2c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1d159bc665cf4d609fc254b62050fced","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e46e85ad270a45d7b9c2630db926f9ba","IPY_MODEL_c3ca734943de4393a64a6dfa8db1a5b5"]}},"1d159bc665cf4d609fc254b62050fced":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e46e85ad270a45d7b9c2630db926f9ba":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0549c582b5f94878b578aec7f8bf5fee","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":109540,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":109540,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff123eb822ef4a53907ea42b90f09c0a"}},"c3ca734943de4393a64a6dfa8db1a5b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b015ff272e74f9d93872faa72681aac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 110k/110k [00:00&lt;00:00, 195kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ea34c8b34b54825bfe168f5f008d77d"}},"0549c582b5f94878b578aec7f8bf5fee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ff123eb822ef4a53907ea42b90f09c0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b015ff272e74f9d93872faa72681aac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6ea34c8b34b54825bfe168f5f008d77d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fcbe9d52d6543eb8dcb1b1b1426cff5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_20bdd119bdf249f58e593a6be2eeb6df","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_eaca4cedaeb74af291ec32906829072f","IPY_MODEL_8c251298faf04c668c9b13e76efd768f"]}},"20bdd119bdf249f58e593a6be2eeb6df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eaca4cedaeb74af291ec32906829072f":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_62b1d2653725436583ae0c7dfe6b5d16","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":624,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":624,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_458f8d3ad9f84393991576087f776857"}},"8c251298faf04c668c9b13e76efd768f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_32b65fbac9d44ca194745201658a7f10","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 624/624 [00:01&lt;00:00, 390B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4b1c07dbc9a492795e6adf47507e226"}},"62b1d2653725436583ae0c7dfe6b5d16":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"458f8d3ad9f84393991576087f776857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32b65fbac9d44ca194745201658a7f10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4b1c07dbc9a492795e6adf47507e226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9067e0128e9148938719b0d2ad2eb904":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d82d30a6a5474ff397b85b9c6b62dea6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f9a0dae054ef475c8dffd5608a019ef6","IPY_MODEL_bbe187e7ef9d4d10b01fbffd7ba533ee"]}},"d82d30a6a5474ff397b85b9c6b62dea6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9a0dae054ef475c8dffd5608a019ef6":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6e4d335274034fac85180fc535babfe3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":411577189,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":411577189,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_084f23c3e860463c841ad0bf97758587"}},"bbe187e7ef9d4d10b01fbffd7ba533ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c33bc8cb92b548818982be5651bb4ea4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 412M/412M [07:26&lt;00:00, 921kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2dafbdb370e54cd0bdd5e6d0c0b5fd67"}},"6e4d335274034fac85180fc535babfe3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"084f23c3e860463c841ad0bf97758587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c33bc8cb92b548818982be5651bb4ea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2dafbdb370e54cd0bdd5e6d0c0b5fd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"k57NK69glC-D","colab_type":"code","outputId":"ef5434cb-d8e7-47b1-b37c-1214354e58c9","executionInfo":{"status":"ok","timestamp":1588345248147,"user_tz":-480,"elapsed":8515,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["!pip install transformers tqdm boto3 requests regex -q"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 573kB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 1.0MB 64.3MB/s \n","\u001b[K     |████████████████████████████████| 3.7MB 75.1MB/s \n","\u001b[K     |████████████████████████████████| 890kB 62.2MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ajnKUlKn0Q6c","colab_type":"code","outputId":"0bc9d6fd-0725-40c3-8664-41d39a4928a2","executionInfo":{"status":"ok","timestamp":1588345273297,"user_tz":-480,"elapsed":33605,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7evedgC80Tjw","colab_type":"code","outputId":"e2834507-668f-42dc-a328-2def4aa0edb1","executionInfo":{"status":"ok","timestamp":1588345273298,"user_tz":-480,"elapsed":33554,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd gdrive/My\\ Drive/Colab Notebooks"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rPplumJEXHcO","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5F00mZWdliqK","colab_type":"code","outputId":"5b10efdf-30a9-4a07-8dcb-7dc12fc97588","executionInfo":{"status":"ok","timestamp":1588345296174,"user_tz":-480,"elapsed":56350,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["df_train = pd.read_excel(\"stock_data/stockdata_withdo_new_fiftycompany_train.xlsx\")\n","df_test = pd.read_excel(\"stock_data/stockdata_withdo_new_fiftycompany_test.xlsx\")\n","df_dev = pd.read_excel(\"stock_data/stockdata_withdo_new_fiftycompany_dev.xlsx\")\n","\n","ratio = len(df_test) / len(df_train)\n","print(\"測試集樣本數 / 訓練集樣本數 = {:.2f} 倍\".format(ratio))\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["測試集樣本數 / 訓練集樣本數 = 0.12 倍\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RGHe1ByJI1_s","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from pandas import DataFrame \n","l1 = []\n","l2 = []\n","\n","for i, row in df_train.iterrows():\n","    if row['start_price'] and row['last_price']:\n","        content = row['content'][:100]\n","        l1.extend([content])\n","        l2.extend([row['labeling']])\n","\n","df_train = DataFrame({'content': l1, 'labeling': l2})\n","\n","l1 = []\n","l2 = []\n","\n","for i, row in df_test.iterrows():\n","    if row['start_price'] and row['last_price']:\n","        content = row['content'][:100]\n","        l1.extend([content])\n","        l2.extend([row['labeling']])\n","    \n","df_test = DataFrame({'content': l1, 'labeling': l2})\n","\n","l1 = []\n","l2 = []\n","\n","for i, row in df_dev.iterrows():\n","    if row['start_price'] and row['last_price']:\n","        content = row['content'][:100]\n","        l1.extend([content])\n","        l2.extend([row['labeling']])\n","    \n","df_dev = DataFrame({'content': l1, 'labeling': l2})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0CjoBUQ5Nj-","colab_type":"code","colab":{}},"source":["# 去除不必要欄位\n","\n","## (測試用)\n","# SAMPLE_FRAC = 0.001\n","# df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=9527)\n","\n","df_train = df_train.reset_index()\n","df_train = df_train.loc[:, ['content', 'labeling']]\n","df_train.columns = ['content', 'labeling']\n","df_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n","\n","df_test = df_test.loc[:, ['content', 'labeling']]\n","df_test.columns = ['content', 'labeling']\n","df_test.to_csv(\"test.tsv\", sep=\"\\t\", index=False)\n","\n","df_dev = df_dev.loc[:, ['content', 'labeling']]\n","df_dev.columns = ['content', 'labeling']\n","df_dev.to_csv(\"dev.tsv\", sep=\"\\t\", index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OlY_-sjNxuAe","colab_type":"code","outputId":"ec6f8d6c-3b6d-481a-c388-95d96fd2138c","executionInfo":{"status":"ok","timestamp":1588345309797,"user_tz":-480,"elapsed":69918,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(df_train))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["71697\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_b8-f0t5tLI0","colab_type":"code","outputId":"315ad0c2-4338-401e-8529-cb384d4c30fb","executionInfo":{"status":"ok","timestamp":1588345316223,"user_tz":-480,"elapsed":76335,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["8b2b8713e4a8454595bc00174d2fe2c2","1d159bc665cf4d609fc254b62050fced","e46e85ad270a45d7b9c2630db926f9ba","c3ca734943de4393a64a6dfa8db1a5b5","0549c582b5f94878b578aec7f8bf5fee","ff123eb822ef4a53907ea42b90f09c0a","4b015ff272e74f9d93872faa72681aac","6ea34c8b34b54825bfe168f5f008d77d"]}},"source":["\"\"\"\n","實作一個可以用來讀取訓練 / 測試集的 Dataset，這是你需要徹底了解的部分。\n","此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n","- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n","- segments_tensor：可以用來識別兩個句子界限的 binary tensor\n","- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n","\"\"\"\n","\n","from torch.utils.data import Dataset\n","from transformers import BertTokenizer\n","import torch\n","\n","PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n","    \n","class StockDataset(Dataset):\n","    # 讀取前處理後的 tsv 檔並初始化一些參數\n","    def __init__(self, mode, tokenizer):\n","        assert mode in [\"train\", \"test\", \"dev\"]  # 一般訓練你會需要 dev set\n","        self.mode = mode\n","        # 大數據你會需要用 iterator=True\n","        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n","        self.len = len(self.df)\n","        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n","    \n","    # 定義回傳一筆訓練 / 測試數據的函式\n","    def __getitem__(self, idx):\n","        if self.mode == \"test\":\n","            content, label = self.df.iloc[idx, :2].values\n","            label_id = label\n","            label_tensor = torch.tensor(label_id)\n","        else:\n","            content, label = self.df.iloc[idx, :2].values\n","            # 將 label 文字也轉換成索引方便轉換成 tensor\n","            label_id = label\n","            label_tensor = torch.tensor(label_id)\n","            \n","        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n","        word_pieces = [\"[CLS]\"]\n","        tokens_a = self.tokenizer.tokenize(content)\n","        word_pieces += tokens_a + [\"[SEP]\"]\n","        len_a = len(word_pieces)\n","                \n","        # 將整個 token 序列轉換成索引序列\n","        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n","        tokens_tensor = torch.tensor(ids)\n","        \n","        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n","        segments_tensor = torch.tensor([0] * len_a , \n","                                        dtype=torch.long)\n","        \n","        return (tokens_tensor, segments_tensor, label_tensor)\n","    \n","    def __len__(self):\n","        return self.len\n","    \n","    \n","# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n","trainset = StockDataset(\"train\", tokenizer=tokenizer)\n","\n","devset = StockDataset(\"dev\", tokenizer=tokenizer)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b2b8713e4a8454595bc00174d2fe2c2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=109540, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F_Weh16Y1Bdd","colab_type":"code","outputId":"5b887e8b-5a1d-4167-c701-b92afdc18db1","executionInfo":{"status":"ok","timestamp":1588345316224,"user_tz":-480,"elapsed":76323,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["# 選擇第一個樣本\n","sample_idx = 1\n","\n","# 將原始文本拿出做比較\n","content, labeling = trainset.df.iloc[sample_idx].values\n","\n","# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n","tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n","\n","# 將 tokens_tensor 還原成文本\n","tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n","combined_text = \"\".join(tokens)\n","\n","# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n","print(f\"\"\"[原始文本]\n","句子 1：{content}\n","分類  ：{labeling}\n","\n","--------------------\n","\n","[Dataset 回傳的 tensors]\n","tokens_tensor  ：{tokens_tensor}\n","\n","segments_tensor：{segments_tensor}\n","\n","label_tensor   ：{label_tensor}\n","\n","--------------------\n","\n","[還原 tokens_tensors]\n","{combined_text}\n","\"\"\")\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[原始文本]\n","句子 1： 澳洲 央行 公佈 現金 利率 目標 蘋果 WWDC 大會 重要 新聞 大立光 5月 營收 3757億 元 為 今年 次 高 i8 鏡頭 7月 開始 出貨 more TPK 5月 營收 7114億 月\n","分類  ：0\n","\n","--------------------\n","\n","[Dataset 回傳的 tensors]\n","tokens_tensor  ：tensor([  101,  4078,  3828,  1925,  6121,  1062,   854,  4412,  7032,  1164,\n","         4372,  4680,  3560,  5981,  3362,   100,  1920,  3298,  7028,  6206,\n","         3173,  5472,  1920,  4989,  1045,   126,  3299,  4245,  3119, 11256,\n","         8161,  1023,  1039,  4158,   791,  2399,  3613,  7770,   151,  8156,\n","         7128,  7531,   128,  3299,  7274,  1993,  1139,  6515,  8384,   100,\n","          126,  3299,  4245,  3119, 12565,  8159,  1023,  3299,   102])\n","\n","segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","\n","label_tensor   ：0\n","\n","--------------------\n","\n","[還原 tokens_tensors]\n","[CLS]澳洲央行公佈現金利率目標蘋果[UNK]大會重要新聞大立光5月營收375##7億元為今年次高i##8鏡頭7月開始出貨more[UNK]5月營收711##4億月[SEP]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eFjB4IKHSkMl","colab_type":"code","colab":{}},"source":["\"\"\"\n","實作可以一次回傳一個 mini-batch 的 DataLoader\n","這個 DataLoader 吃我們上面定義的 `FakeNewsDataset`，\n","回傳訓練 BERT 時會需要的 4 個 tensors：\n","- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n","- segments_tensors: (batch_size, max_seq_len_in_batch)\n","- masks_tensors   : (batch_size, max_seq_len_in_batch)\n","- label_ids       : (batch_size)\n","\"\"\"\n","\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n","# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n","# - tokens_tensor\n","# - segments_tensor\n","# - label_tensor\n","# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n","def create_mini_batch(samples):\n","    tokens_tensors = [s[0] for s in samples]\n","    segments_tensors = [s[1] for s in samples]\n","    \n","    # 訓練集有 labels\n","    if samples[0][2] is not None:\n","        label_ids = torch.stack([s[2] for s in samples])\n","    else:\n","        label_ids = None\n","    \n","    # zero pad 到同一序列長度\n","    tokens_tensors = pad_sequence(tokens_tensors, \n","                                  batch_first=True)\n","    segments_tensors = pad_sequence(segments_tensors, \n","                                    batch_first=True)\n","    \n","    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n","    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n","    masks_tensors = torch.zeros(tokens_tensors.shape, \n","                                dtype=torch.long)\n","    masks_tensors = masks_tensors.masked_fill(\n","        tokens_tensors != 0, 1)\n","    \n","    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n","\n","\n","# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n","# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n","BATCH_SIZE = 16\n","trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n","                         collate_fn=create_mini_batch)\n","\n","devloader = DataLoader(devset, batch_size=BATCH_SIZE, \n","                        collate_fn=create_mini_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aKj__cvtTpCw","colab_type":"code","outputId":"c3d198ee-51a0-439f-f07d-33305e5e8867","executionInfo":{"status":"ok","timestamp":1588345316225,"user_tz":-480,"elapsed":76307,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":538}},"source":["data = next(iter(trainloader))\n","\n","tokens_tensors, segments_tensors, \\\n","    masks_tensors, label_ids = data\n","\n","print(f\"\"\"\n","tokens_tensors.shape   = {tokens_tensors.shape} \n","{tokens_tensors}\n","------------------------\n","segments_tensors.shape = {segments_tensors.shape}\n","{segments_tensors}\n","------------------------\n","masks_tensors.shape    = {masks_tensors.shape}\n","{masks_tensors}\n","------------------------\n","label_ids.shape        = {label_ids.shape}\n","{label_ids}\n","\"\"\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","tokens_tensors.shape   = torch.Size([16, 65]) \n","tensor([[ 101,  464, 5836,  ..., 7065, 6121,  102],\n","        [ 101, 4078, 3828,  ...,    0,    0,    0],\n","        [ 101,  126, 7442,  ...,  102,    0,    0],\n","        ...,\n","        [ 101,  127, 1168,  ...,    0,    0,    0],\n","        [ 101, 1378, 4948,  ...,    0,    0,    0],\n","        [ 101, 1912, 6536,  ...,    0,    0,    0]])\n","------------------------\n","segments_tensors.shape = torch.Size([16, 65])\n","tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]])\n","------------------------\n","masks_tensors.shape    = torch.Size([16, 65])\n","tensor([[1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])\n","------------------------\n","label_ids.shape        = torch.Size([16])\n","tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1])\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VY9JrFppNkNZ","colab_type":"code","outputId":"bc5c8fa6-99fe-4333-8456-54bfcab6bf37","executionInfo":{"status":"ok","timestamp":1588345357124,"user_tz":-480,"elapsed":117196,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["3fcbe9d52d6543eb8dcb1b1b1426cff5","20bdd119bdf249f58e593a6be2eeb6df","eaca4cedaeb74af291ec32906829072f","8c251298faf04c668c9b13e76efd768f","62b1d2653725436583ae0c7dfe6b5d16","458f8d3ad9f84393991576087f776857","32b65fbac9d44ca194745201658a7f10","a4b1c07dbc9a492795e6adf47507e226","9067e0128e9148938719b0d2ad2eb904","d82d30a6a5474ff397b85b9c6b62dea6","f9a0dae054ef475c8dffd5608a019ef6","bbe187e7ef9d4d10b01fbffd7ba533ee","6e4d335274034fac85180fc535babfe3","084f23c3e860463c841ad0bf97758587","c33bc8cb92b548818982be5651bb4ea4","2dafbdb370e54cd0bdd5e6d0c0b5fd67"]}},"source":["from transformers import BertForSequenceClassification\n","\n","PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n","NUM_LABELS = 3\n","\n","model = BertForSequenceClassification.from_pretrained(\n","    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n","\n","# model = torch.load('Bert_model/Bert50_300_25.pkl')\n","\n","#clear_output()\n","\n","# high-level 顯示此模型裡的 modules\n","print(\"\"\"\n","name            module\n","----------------------\"\"\")\n","for name, module in model.named_children():\n","    if name == \"bert\":\n","        for n, _ in module.named_children():\n","            print(f\"{name}:{n}\")\n","    else:\n","        print(\"{:15} {}\".format(name, module))"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fcbe9d52d6543eb8dcb1b1b1426cff5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=624, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9067e0128e9148938719b0d2ad2eb904","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=411577189, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","name            module\n","----------------------\n","bert:embeddings\n","bert:encoder\n","bert:pooler\n","dropout         Dropout(p=0.1, inplace=False)\n","classifier      Linear(in_features=768, out_features=3, bias=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fI1uUQmkRuJz","colab_type":"code","outputId":"db2884eb-f287-40ed-a2a2-1caf2fad3d9c","executionInfo":{"status":"ok","timestamp":1588345357125,"user_tz":-480,"elapsed":117185,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.config"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_num_labels\": 3,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bad_words_ids\": null,\n","  \"bos_token_id\": null,\n","  \"decoder_start_token_id\": null,\n","  \"directionality\": \"bidi\",\n","  \"do_sample\": false,\n","  \"early_stopping\": false,\n","  \"eos_token_id\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"is_encoder_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 0,\n","  \"model_type\": \"bert\",\n","  \"no_repeat_ngram_size\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"prefix\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"task_specific_params\": null,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 21128\n","}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"1NorrzUbSLai","colab_type":"code","outputId":"f570cf24-8ae0-49a5-e47f-dca67ea4cc7e","executionInfo":{"status":"ok","timestamp":1588345372950,"user_tz":-480,"elapsed":132964,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\"\"\"\n","定義一個可以針對特定 DataLoader 取得模型預測結果以及分類準確度的函式\n","\n","GPU 跑會有 cuda runtime error 的問題，所以先使用 CPU 跑不會有狀況!\n","\n","\"\"\"\n","\n","def get_predictions(model, dataloader, compute_acc=False):\n","    predictions = None\n","    correct = 0\n","    total = 0\n","    tp = 0\n","    tn = 0\n","    fp = 0\n","    fn = 0\n","      \n","    with torch.no_grad():\n","        # 遍巡整個資料集\n","        for data in dataloader:\n","            # 將所有 tensors 移到 GPU 上\n","            if next(model.parameters()).is_cuda:\n","                data = [t.to(\"cuda:0\") for t in data if t is not None]\n","            \n","            \n","            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n","            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n","            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n","            outputs = model(input_ids=tokens_tensors, \n","                            token_type_ids=segments_tensors, \n","                            attention_mask=masks_tensors)\n","            \n","            logits = outputs[0]\n","            _, pred = torch.max(logits.data, 1)\n","            \n","            # 用來計算訓練集的分類準確率\n","            if compute_acc:\n","                labels = data[3]\n","                total += labels.size(0)\n","                correct += (pred == labels).sum().item()\n","\n","                tp += (labels * pred).sum().to(torch.float32)\n","                tn += ((1 - labels) * (1 - pred)).sum().to(torch.float32)\n","                fp += ((1 - labels) * pred).sum().to(torch.float32)\n","                fn += (labels * (1 - pred)).sum().to(torch.float32)\n","                                \n","            # 將當前 batch 記錄下來\n","            if predictions is None:\n","                predictions = pred\n","            else:\n","                predictions = torch.cat((predictions, pred))\n","    \n","    if compute_acc:\n","        acc = correct / total\n","\n","        #epsilon = 1e-7\n","        precision = tp / (tp + fp)\n","        recall = tp / (tp + fn)\n","        fscore = (2 * precision * recall) / (precision + recall)\n","        return predictions, acc, precision, recall, fscore    \n","    return predictions\n","  \n","\n","# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)\n","model = model.to(device)\n","# _, acc, precision, recall, fscore = get_predictions(model, trainloader, compute_acc=True)\n","# print(\"classification acc:\", acc)\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["device: cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y-2pfrzOSSCY","colab_type":"code","outputId":"2f4bee54-98cd-4980-b6c2-6489cc7bb98e","executionInfo":{"status":"ok","timestamp":1588345372950,"user_tz":-480,"elapsed":132951,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["def get_learnable_params(module):\n","    return [p for p in module.parameters() if p.requires_grad]\n","     \n","model_params = get_learnable_params(model)\n","clf_params = get_learnable_params(model.classifier)\n","\n","print(f\"\"\"\n","整個分類模型的參數量：{sum(p.numel() for p in model_params)}\n","線性分類器的參數量：{sum(p.numel() for p in clf_params)}\n","\"\"\")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\n","整個分類模型的參數量：102269955\n","線性分類器的參數量：2307\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"omWcBy9zWADw","colab_type":"code","outputId":"43b0377a-ab8b-460f-eba2-5176c0450bcd","executionInfo":{"status":"ok","timestamp":1588059265974,"user_tz":-480,"elapsed":1128409,"user":{"displayName":"邱彥誠","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxoVsIWS4f1UTPVY9IWXIE-mN8CIJ5Mt7W8Ubfkw=s64","userId":"15689487919036263626"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["%%time\n","\n","import time\n","\n","# 訓練模式\n","model.train()\n","\n","# 使用 Adam Optim 更新整個分類模型的參數\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","\n","EPOCHS = 100 # 預設為 6\n","for epoch in range(EPOCHS):\n","    \n","    tStart=time.time()\n","    running_loss = 0.0\n","    for data in trainloader:\n","        \n","        tokens_tensors, segments_tensors, \\\n","        masks_tensors, labels = [t.to(device) for t in data]\n","\n","        # 將參數梯度歸零\n","        optimizer.zero_grad()\n","        \n","        # forward pass\n","        outputs = model(input_ids=tokens_tensors, \n","                        token_type_ids=segments_tensors, \n","                        attention_mask=masks_tensors, \n","                        labels=labels)\n","\n","        loss = outputs[0]\n","        # backward\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 紀錄當前 batch loss\n","        running_loss += loss.item()\n"," \n","    # 計算分類準確率\n","    if (epoch+1) % 5 == 0 and epoch > 0 :\n","        # 計算分類準確率\n","        _, acc, precision, recall, fscore = get_predictions(model, devloader, compute_acc=True)\n","\n","        print('[epoch %d] loss: %.3f, acc: %.3f, precision: %.3f, recall: %.3f, fscore: %.3f' % \n","              (epoch + 1, running_loss, acc, precision, recall, fscore))\n","    \n","        tEnd=time.time()\n","        print(\"\\n It cost %f sec\"%(tEnd-tStart))\n","torch.save(model, 'Bert_new50.pkl')\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[epoch 5] loss: 2065.128, acc: 0.606, precision: 0.619, recall: 0.790, fscore: 0.694\n","\n"," It cost 646.679185 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBxrm7vZlmvA","colab_type":"code","colab":{}},"source":["## 儲存model的參數\n","# torch.save(model.state_dict(), 'Bert_withdo50.pkl')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGchBtY7VTyq","colab_type":"code","colab":{}},"source":["%%time\n","\n","# 建立測試集\n","testset = StockDataset(\"test\", tokenizer=tokenizer)\n","testloader = DataLoader(testset, batch_size=32, \n","                        collate_fn=create_mini_batch)\n","\n","_, acc, precision, recall, fscore = get_predictions(model, testloader, compute_acc=True)\n","\n","print('acc: %.3f, precision: %.3f, recall: %.3f, fscore: %.3f' % \n","      (acc, precision, recall, fscore))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yrULAPryQ4u","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}